{
	"projects": [{
			"name": "Together Apart",
			"subdomain": "together_apart",
			"category": ["tangible", "networked", "participatory"],
			"subtitle": "Co-Designing A Robot Interface for Remote Co-Design",
			"collaborators": ["Zach Schwemler", "Allison Druin", "Jason Yip", "Amanda Huynh", "Daniel Leithinger"],
			"abstract": "A long term co-design project with KidsTeam UW to create a remote and hybrid tangible co-design tool. We utilize Sony toio robots to build a networked robot platform that child designers and their adult design partners can use to collaborate in real time. Through this project, we gain insights about tangible co-design tools for remote and hybrid contexts.",
			"description": ["In HCI, children have been active participants in co-designing future technologies for other children. Most studies in co-design (prior to COVID-19), focused on co-located in-person sessions that involved physical techniques, such as hand-drawn and crafted prototypes, acting out scenarios, and playing movement games to generate ideas. However, these physically proximal activities are not possible online. This lack of physical engagement creates barriers and leaves children feeling less creative and engaged in the remote co-design process.", "To workaround this situation in which children are co-designing online, we have worked with KidsTeam UW to create another option for remote co-design: tangible interfaces for remote co-design. Our project, Together Apart, uses toio tabletop robots and a tablet interface to add a tangible dimension to online co-design. When using our system, our child design partners acted in an engaged manner not typically seen in remote settings.", "While working together online, KidsTeam UW children used our toio robotics system to design games, swarm robot expressions, and create physical art together. For our workshop contribution, we will showcase some of our work-in-progress and develop potential collaborations for tangible online co-design. In the future we plan to move from a fully remote environment to a hybrid environment for co-design. We will engage in conversations with KidsTeam UW about how tangible interfaces for hybrid environments differ from fully online contexts."],
			"mainimg": "tapart.jpg",
			"images": ["mario and luigi cropped.PNG", "draw 1.PNG", "dance actually.PNG", "robot marbles.PNG"]
		},

		{
			"name": "Presence Mat",
			"subdomain": "presence_mat",
			"category": ["embodied"],
			"subtitle": "Low-Cost Room-Scale Radar for the Home with Off-The-Shelf Hardware",
			"collaborators": ["Daniel Leithinger"],
			"abstract": "A system built with off-the-shelf Ultra-High frequency RFID to create a room-scale radar system. Using deep learning Presence Mat approximates body position for yoga-based interaction.",
			"description": ["As virtual assistants and remote classes become increasingly common in fitness, so too does the need to reliably recognize human posture and activity. We designed a system that explores how device-free Ultra-High Frequency Radio Frequency Identification (UHF RFID) enables low-cost fitness tracking without the trade-offs of worn sensors or cameras.", "Because UHF RFID systems are subject to signal shielding by the human body, it is possible to utilize returned signal strength from passive tags to infer user position. However, because previous designs only support low resolution activity recognition, application of this technology to fitness tracking is limited.", "We present Presence Mat, a demonstration of our novel task - specific approach to UHF RFID activity recognition.With this work, we present a high accuracy, high resolution device - free interface built with unmodified off - the - shelf hardware.In designing for a single application: mat - based exercises, we demonstrate significant performance improvements over previous device - free UHF RFID activity trackers."],
				"mainimg": "mat.jpg",
				"images": ["placeholder.jpg", "placeholder.jpg", "placeholder.jpg"]
			},

			{
				"name": "Cyber Garden",
				"subdomain": "cyber_garden",
				"category": ["tangible", "participatory"],
				"subtitle": "Ambient Community Wellness Display ",
				"collaborators": ["Ruojia Sun", "Sandra Bae", "Chris Hill", "Steve Voida"],
				"abstract": "An ambient display that invites students and faculty to share and reflect on their stress as a community. With a combination of self-reported and biometric data, the community controls robotic flowers that close or bloom as a representation of stress in the community.",
				"description": ["We are inspired by related work in ambient displays as a promising technology for community wellness interfaces. Ambient displays are particularly applicable to community wellness, since they are well-suited for enabling continuous, background awareness of general states of large systems. There have been several works which use ambient displays to support mental wellness and stress management; for example, MoodLight is an interactive ambient lighting system that responds to epidermal activity biosensor data related to the userâ€™s stress level. ", "In particular, we draw from works which use plants in ambient displays, since plants can potentially increase emotional engagement from users while serving as an ambient, naturally-informative display of aggregated local information. We leverage previous workshops conducted with graduate students to ground our approach. When asked about burnout, these graduate students shared a desire to reach out for help, but reported not having a clear mechanism to do so. Additionally, these students reported that they would feel less alone in their difficult emotions if there was a way to see the challenging states of others.", "With Cyber Garden, we design an ambient display for graduate students to report personal stress through biometric and self-reported metrics. We use this data to create an anonymized visualization of blooming flowers."],
				"mainimg": "cgarden.jpeg",
				"images": ["garden_display.jpeg", "garden_full.jpeg"]
			},

			{
				"name": "Scent Bots",
				"subdomain": "scent_bots",
				"category": ["networked", "tangible"],
				"subtitle": "Automatic Roving Scents for Ambient Telepresence using Object Recognition",
				"collaborators": ["Chris Hill", "Daniel Leithinger"],
				"abstract": "A swarm robot modification to create spatial scent for ambient telepresence. Using a top down camera and object recognition algorithm, the position and smell of an item placed on a tabletop can be simulated in a remote space. With Scent Bots design a mechanism to bring scent to a swarm robotics context while also exploring the nature of spatial scent for ambient telepresence.",
				"description": ["The THING Lab functions remotely 2/3 of the time. Our advisor, Daniel, works from New York City, our collaborators are stationed around the world, and our lab is housed in the ATLAS Institute at CU Boulder. With Scent Bots, we explore the combination of location and scent for ambient telepresence.", "The system pairs video calling, object recognition, a top-down projector, and robots to connect two tabletops through scent. Each table is captured via a top-down webcam, which is projected on the remote partner's table. An object placed on one table triggers the remote Scent Bot. This robot will move to the position where the smelly item, say a fresh cup of coffee, is located on the remote table and begin release a corresponding scent."],
				"mainimg": "sbots.jpg",
				"images": ["placeholder.jpg", "placeholder.jpg", "placeholder.jpg"]
			},

			{
				"name": "DOT",
				"subdomain": "dot",
				"category": ["tangible", "toolkit"],
				"subtitle": "Device for Object Based Telepresence",
				"collaborators": ["Ruhan Yang", "Daniel Leithinger"],
				"abstract": "A platform that utilizes tabletop swarm robots to create a dynamic tangible display. The system recognizes the identity of objects placed on the surface, and a paired display reacts to this configuration. Created for the 2021 UIST Student Innovation Challenge.",
				"description": ["DOT, is a tabletop tangible display that detects and integrates everyday objects. Using swarm robots, we create a scalable, portable tangible interface. Two toio robots are combined with an assembly that contains a magnet with a lift screw, allowing the system to move magnet-containing objects placed on the tabletop. The resulting platform can be used for tangible play, communication, and co-creation.", "In contrast to previous approaches to tangible displays that integrate objects using computer vision using fixed cameras, the toios in DOT recognize objects using markers placed on the base of the object. In this way, the system is portable, because it does not require a stationary setup for object recognition."],
				"mainimg": "dot.jpg",
				"images": ["placeholder.jpg", "placeholder.jpg", "placeholder.jpg"]
			},

			{
				"name": "VTTV",
				"subdomain": "vttv",
				"category": ["tangible", "toolkit"],
				"subtitle": "Vibrotactile Tongue Display",
				"collaborators": ["Mary Etta West", "Netta Ofer", "Sandra Bae", "Chris Hill"],
				"abstract": "VTTV is a seven segment vibrotactile display that combines taste and vibration to create haptic art for the tongue. The system provides a unique platform for crafting playful, flavorful, vibrotactile experiences. This project recieved honorable mention in the Student Design Competition at World Haptics Conference 2020.",
				"description": ["The Vibrotactile Tongue Vision (VTTV) system is an open-source programmable tongue display unit (TDU) that augments visual and auditory experiences through haptic feedback. VTTV is designed to enable those without embedded systems skills to fabricate a TDU, controller, and craft tactile experiences easily. Experienced engineers, researchers, makers, and artists can hack VTTV to be an actuator in their projects. The project will also includes a controller to program haptic patterns directly to the VTTV system.", "TDUs typically use electrotactile stimulation to display information to the user. These systems produce sensations by generating voltage pulses from electrodes to the userâ€™s tongue. Commercial TDU systems are closed source, prohibitively expensive, and compromise haptic resolution for user comfort. Cyborg Crafts proposes an alternative to electrotactile TDUs, a novel system that uses ERM motors for actuation. Cyborg Craftâ€™s goal is to enable anyone to fabricate their own TDU using easily accessible materials with affordable off-the-shelf tools. The merit of this project is a replicable design with instructions on free-to-use online platforms such as Instructables. This will enable makers, students, artists, hackers, and researchers to fabricate and implement a TDU as an output device.", "With VTTV, we introduce a new genre of human augmentation: sensory crafting. Sensory crafting is the crafting of a sensory experience to be shared from one human's sensory modality (e.g., visual, auditory) to another through a mediating device. VTTV encourages users to reflect on their own sensory experiences and then program actuation to be shared."],
				"mainimg": "vttv.jpeg",
				"images": ["TDU.PNG", "vttv_unsealed.jpg", "vttv_sealed.jpeg", "vttv_candy.jpeg", "vttv_chris.jpeg"]
			},

			{
				"name": "Everything Instrument",
				"subdomain": "everything_instrument",
				"category": ["tangible", "toolkit"],
				"subtitle": "Turn Anything Into an Instrument",
				"collaborators": ["Ruhan Yang"],
				"abstract": "A platform that allows people to turn anything into an instrument using copper tape. After applying copper tape to everyday household objects, users attach their creation to Everything Instrument, using buttons to customize the pitch and character of their sound. Designed for the SynthUX 2021 hackathon.",
				"description": ["Using capacitive touch, PaperMagnets, and amicrophone, we create amodular system that allows any object to become a part of the orchestra. We demonstrate this platform by building a melodica, keyboard, cello, trombone, and percussion. The system utilizes the capacitive touch breakout to create a 12 tone scale. From there, we utilize up to six buttons to modify the sound. In the case of the melodica and keyboard, the buttons can be used to change octaves. In the case of the cello, the buttons function as strings. The wind instruments utilize a microphone in the mouthpiece to detect whether and how hard air is being blown into the instrument."],
				"mainimg": "ei.jpeg",
				"images": ["placeholder.jpg", "placeholder.jpg", "placeholder.jpg"]
			}
		]



	}
